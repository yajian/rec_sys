{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/mnt/bkslf/ctr/deepfm/train.csv'\n",
    "test_file = '/mnt/bkslf/ctr/deepfm/test.csv'\n",
    "NUMERIC_COLS = [\n",
    "    \"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\",\n",
    "    \"ps_car_12\", \"ps_car_13\", \"ps_car_14\", \"ps_car_15\"\n",
    "]\n",
    "IGNORE_COLS = [\n",
    "    \"id\", \"target\",\n",
    "    \"ps_calc_01\", \"ps_calc_02\", \"ps_calc_03\", \"ps_calc_04\",\n",
    "    \"ps_calc_05\", \"ps_calc_06\", \"ps_calc_07\", \"ps_calc_08\",\n",
    "    \"ps_calc_09\", \"ps_calc_10\", \"ps_calc_11\", \"ps_calc_12\",\n",
    "    \"ps_calc_13\", \"ps_calc_14\",\n",
    "    \"ps_calc_15_bin\", \"ps_calc_16_bin\", \"ps_calc_17_bin\",\n",
    "    \"ps_calc_18_bin\", \"ps_calc_19_bin\", \"ps_calc_20_bin\"\n",
    "]\n",
    "\n",
    "dfTrain = pd.read_csv(train_file)\n",
    "dfTest = pd.read_csv(test_file)\n",
    "# print(dfTrain.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangyajian/repo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([dfTrain, dfTest])\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {}\n",
    "total_feature = 0\n",
    "for col in df.columns:\n",
    "    if col in IGNORE_COLS:\n",
    "        continue\n",
    "    elif col in NUMERIC_COLS:\n",
    "        feature_dict[col] = total_feature\n",
    "        total_feature += 1\n",
    "    else:\n",
    "        unique_val = df[col].unique()\n",
    "        feature_dict[col] = dict(zip(unique_val,range(total_feature,len(unique_val) + total_feature)))\n",
    "        total_feature += len(unique_val)\n",
    "# print(total_feature)\n",
    "# print(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'target', 'ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03',\n",
      "       'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin',\n",
      "       'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
      "       'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15',\n",
      "       'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01',\n",
      "       'ps_reg_02', 'ps_reg_03', 'ps_car_01_cat', 'ps_car_02_cat',\n",
      "       'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat',\n",
      "       'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_10_cat',\n",
      "       'ps_car_11_cat', 'ps_car_11', 'ps_car_12', 'ps_car_13', 'ps_car_14',\n",
      "       'ps_car_15', 'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04',\n",
      "       'ps_calc_05', 'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09',\n",
      "       'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
      "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
      "       'ps_calc_19_bin', 'ps_calc_20_bin'],\n",
      "      dtype='object')\n",
      "(10000, 37)\n",
      "(10000, 37)\n",
      "   ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
      "0        175            183        188            200            203   \n",
      "1        176            184        189            201            203   \n",
      "\n",
      "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ps_ind_10_bin  \\\n",
      "0            211            213            215            217            219   \n",
      "1            211            214            216            217            219   \n",
      "\n",
      "   ...  ps_car_07_cat  ps_car_08_cat  ps_car_09_cat  ps_car_10_cat  \\\n",
      "0  ...             49             52             54             60   \n",
      "1  ...             49             53             55             60   \n",
      "\n",
      "   ps_car_11_cat  ps_car_11  ps_car_12  ps_car_13  ps_car_14  ps_car_15  \n",
      "0             67         63        171        172        173        174  \n",
      "1             68         64        171        172        173        174  \n",
      "\n",
      "[2 rows x 37 columns]\n",
      "   ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
      "0          1              1          1              1              1   \n",
      "1          1              1          1              1              1   \n",
      "\n",
      "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ps_ind_10_bin  \\\n",
      "0              1              1              1              1              1   \n",
      "1              1              1              1              1              1   \n",
      "\n",
      "   ...  ps_car_07_cat  ps_car_08_cat  ps_car_09_cat  ps_car_10_cat  \\\n",
      "0  ...              1              1              1              1   \n",
      "1  ...              1              1              1              1   \n",
      "\n",
      "   ps_car_11_cat  ps_car_11  ps_car_12  ps_car_13  ps_car_14  ps_car_15  \n",
      "0              1          1   0.400000   0.883679   0.370810   3.605551  \n",
      "1              1          1   0.316228   0.618817   0.388716   2.449490  \n",
      "\n",
      "[2 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dfTrain.columns)\n",
    "train_y = dfTrain[['target']].values.tolist()\n",
    "dfTrain.drop(['target','id'],axis=1,inplace=True)\n",
    "train_feature_index = dfTrain.copy()\n",
    "train_feature_value = dfTrain.copy()\n",
    "\n",
    "for col in train_feature_index.columns:\n",
    "    if col in IGNORE_COLS:\n",
    "        train_feature_index.drop(col,axis=1,inplace=True)\n",
    "        train_feature_value.drop(col,axis=1,inplace=True)\n",
    "        continue\n",
    "    elif col in NUMERIC_COLS:\n",
    "        train_feature_index[col] = feature_dict[col]\n",
    "    else:\n",
    "        train_feature_index[col] = train_feature_index[col].map(feature_dict[col])\n",
    "        train_feature_value[col] = 1\n",
    "print(train_feature_index.shape)\n",
    "print(train_feature_value.shape)\n",
    "print(train_feature_index.head(2))\n",
    "print(train_feature_value.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n",
      "       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n",
      "       'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin',\n",
      "       'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n",
      "       'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n",
      "       'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n",
      "       'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n",
      "       'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n",
      "       'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n",
      "       'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n",
      "       'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n",
      "       'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n",
      "       'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n",
      "       'ps_calc_20_bin'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dfTest.columns)\n",
    "test_ids = dfTest['id'].values.tolist()\n",
    "dfTest.drop(['id'],axis=1,inplace=True)\n",
    "\n",
    "test_feature_index = dfTest.copy()\n",
    "test_feature_value = dfTest.copy()\n",
    "\n",
    "for col in test_feature_index.columns:\n",
    "    if col in IGNORE_COLS:\n",
    "        test_feature_index.drop(col,axis=1,inplace=True)\n",
    "        test_feature_value.drop(col,axis=1,inplace=True)\n",
    "        continue\n",
    "    elif col in NUMERIC_COLS:\n",
    "        test_feature_index[col] = feature_dict[col]\n",
    "    else:\n",
    "        test_feature_index[col] = test_feature_index[col].map(feature_dict[col])\n",
    "        test_feature_value[col] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\"\"\"模型参数\"\"\"\n",
    "dfm_params = {\n",
    "    \"use_fm\":True,\n",
    "    \"use_deep\":True,\n",
    "    \"embedding_size\":8,\n",
    "    \"dropout_fm\":[1.0,1.0],\n",
    "    \"deep_layers\":[32,32],\n",
    "    \"dropout_deep\":[0.5,0.5,0.5],\n",
    "    \"deep_layer_activation\":tf.nn.relu,\n",
    "    \"epoch\":30,\n",
    "    \"batch_size\":1024,\n",
    "    \"learning_rate\":0.001,\n",
    "    \"optimizer\":\"adam\",\n",
    "    \"batch_norm\":1,\n",
    "    \"batch_norm_decay\":0.995,\n",
    "    \"l2_reg\":0.01,\n",
    "    \"verbose\":True,\n",
    "    \"eval_metric\":'gini_norm',\n",
    "    \"random_seed\":3\n",
    "}\n",
    "dfm_params['feature_size'] = total_feature\n",
    "dfm_params['field_size'] = len(train_feature_index.columns)\n",
    "print(total_feature)\n",
    "print(len(train_feature_index.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings (254, 8)\n",
      "embeddings (10000, 37, 8)\n",
      "reshaped_feat_value (10000, 37, 1)\n",
      "embeddings (10000, 37, 8)\n",
      "(10000, 296)\n",
      "epoch 0,loss is 0.6223142\n",
      "epoch 1,loss is 0.6045967\n",
      "epoch 2,loss is 0.58759487\n",
      "epoch 3,loss is 0.5713424\n",
      "epoch 4,loss is 0.55611926\n",
      "epoch 5,loss is 0.54199654\n",
      "epoch 6,loss is 0.52845925\n",
      "epoch 7,loss is 0.5152542\n",
      "epoch 8,loss is 0.50230145\n",
      "epoch 9,loss is 0.48956558\n",
      "epoch 10,loss is 0.4774502\n",
      "epoch 11,loss is 0.46571875\n",
      "epoch 12,loss is 0.45418468\n",
      "epoch 13,loss is 0.4428304\n",
      "epoch 14,loss is 0.4315324\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dc26d632bc0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m         epoch_loss,_ = sess.run([loss,optimizer],feed_dict={feat_index:train_feature_index,\n\u001b[1;32m     97\u001b[0m                              \u001b[0mfeat_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_feature_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                              label:train_y})\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch %s,loss is %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feat_index = tf.placeholder(tf.int32, shape=[10000,37],name='feat_index')\n",
    "feat_value = tf.placeholder(tf.float32, shape=[10000,37],name='feat_value')\n",
    "label = tf.placeholder(tf.float32, shape=[None, 1], name='label')\n",
    "weights = dict()\n",
    "#embeddings\n",
    "weights['feature_embeddings'] = tf.Variable(\n",
    "    tf.random_normal([dfm_params['feature_size'],dfm_params['embedding_size']],0.0,0.01),\n",
    "    name='feature_embeddings')\n",
    "weights['feature_bias'] = tf.Variable(tf.random_normal([dfm_params['feature_size'],1],0.0,1.0),name='feature_bias')\n",
    "\n",
    "#deep layers\n",
    "num_layer = len(dfm_params['deep_layers'])\n",
    "input_size = dfm_params['field_size'] * dfm_params['embedding_size']\n",
    "glorot = np.sqrt(2.0/(input_size + dfm_params['deep_layers'][0]))\n",
    "\n",
    "weights['layer_0'] = tf.Variable(\n",
    "    np.random.normal(loc=0,scale=glorot,size=(input_size,dfm_params['deep_layers'][0])),dtype=np.float32\n",
    ")\n",
    "weights['bias_0'] = tf.Variable(\n",
    "    np.random.normal(loc=0,scale=glorot,size=(1,dfm_params['deep_layers'][0])),dtype=np.float32\n",
    ")\n",
    "for i in range(1,num_layer):\n",
    "    glorot = np.sqrt(2.0 / (dfm_params['deep_layers'][i - 1] + dfm_params['deep_layers'][i]))\n",
    "    weights[\"layer_%d\" % i] = tf.Variable(\n",
    "        np.random.normal(loc=0, scale=glorot, size=(dfm_params['deep_layers'][i - 1], dfm_params['deep_layers'][i])),\n",
    "        dtype=np.float32)  # layers[i-1] * layers[i]\n",
    "    weights[\"bias_%d\" % i] = tf.Variable(\n",
    "        np.random.normal(loc=0, scale=glorot, size=(1, dfm_params['deep_layers'][i])),\n",
    "        dtype=np.float32)  # 1 * layer[i]\n",
    "    \n",
    "# final concat projection layer\n",
    "\n",
    "if dfm_params['use_fm'] and dfm_params['use_deep']:\n",
    "    input_size = dfm_params['field_size'] + dfm_params['embedding_size'] + dfm_params['deep_layers'][-1]\n",
    "elif dfm_params['use_fm']:\n",
    "    input_size = dfm_params['field_size'] + dfm_params['embedding_size']\n",
    "elif dfm_params['use_deep']:\n",
    "    input_size = dfm_params['deep_layers'][-1]\n",
    "\n",
    "glorot = np.sqrt(2.0/(input_size + 1))\n",
    "weights['concat_projection'] = tf.Variable(np.random.normal(loc=0,scale=glorot,size=(input_size,1)),dtype=np.float32)\n",
    "weights['concat_bias'] = tf.Variable(tf.constant(0.01),dtype=np.float32)\n",
    "\n",
    "\"\"\"embedding\"\"\"\n",
    "print('embeddings',weights['feature_embeddings'].get_shape())\n",
    "embeddings = tf.nn.embedding_lookup(weights['feature_embeddings'],feat_index)\n",
    "print('embeddings',embeddings.get_shape())\n",
    "\n",
    "reshaped_feat_value = tf.reshape(feat_value,shape=[-1,dfm_params['field_size'],1])\n",
    "print('reshaped_feat_value',reshaped_feat_value.shape)\n",
    "\n",
    "embeddings = tf.multiply(embeddings,reshaped_feat_value)\n",
    "\n",
    "print('embeddings',embeddings.shape)\n",
    "\n",
    "\"\"\"fm part\"\"\"\n",
    "fm_first_order = tf.nn.embedding_lookup(weights['feature_bias'],feat_index)\n",
    "fm_first_order = tf.reduce_sum(tf.multiply(fm_first_order,reshaped_feat_value),2)\n",
    "\n",
    "summed_features_emb = tf.reduce_sum(embeddings,1)\n",
    "summed_features_emb_square = tf.square(summed_features_emb)\n",
    "\n",
    "squared_features_emb = tf.square(embeddings)\n",
    "squared_sum_features_emb = tf.reduce_sum(squared_features_emb,1)\n",
    "\n",
    "fm_second_order = 0.5 * tf.subtract(summed_features_emb_square,squared_sum_features_emb)\n",
    "\n",
    "\n",
    "\"\"\"deep part\"\"\"\n",
    "y_deep = tf.reshape(embeddings,shape=[-1,dfm_params['field_size'] * dfm_params['embedding_size']])\n",
    "print(y_deep.shape)\n",
    "for i in range(0,len(dfm_params['deep_layers'])):\n",
    "    y_deep = tf.add(tf.matmul(y_deep,weights[\"layer_%d\" %i]), weights[\"bias_%d\"%i])\n",
    "    y_deep = tf.nn.relu(y_deep)\n",
    "    \n",
    "    \n",
    "\"\"\"final layer\"\"\"\n",
    "if dfm_params['use_fm'] and dfm_params['use_deep']:\n",
    "    concat_input = tf.concat([fm_first_order,fm_second_order,y_deep],axis=1)\n",
    "elif dfm_params['use_fm']:\n",
    "    concat_input = tf.concat([fm_first_order,fm_second_order],axis=1)\n",
    "elif dfm_params['use_deep']:\n",
    "    concat_input = y_deep\n",
    "    \n",
    "out = tf.nn.sigmoid(tf.add(tf.matmul(concat_input,weights['concat_projection']),weights['concat_bias']))\n",
    "\n",
    "\"\"\"loss and optimizer\"\"\"\n",
    "loss = tf.losses.log_loss(tf.reshape(label,(-1,1)), out)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=dfm_params['learning_rate'], beta1=0.9, beta2=0.999,\n",
    "                                                        epsilon=1e-8).minimize(loss)\n",
    "\n",
    "\"\"\"train\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        epoch_loss,_ = sess.run([loss,optimizer],feed_dict={feat_index:train_feature_index,\n",
    "                             feat_value:train_feature_value,\n",
    "                             label:train_y})\n",
    "        print(\"epoch %s,loss is %s\" % (str(i),str(epoch_loss)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
