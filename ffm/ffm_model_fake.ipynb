{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import logging\n",
    "import pickle\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_representation(sample, fields_dict, array_length):\n",
    "    \"\"\"\n",
    "    One hot presentation for every sample data\n",
    "    :param fields_dict: fields value to array index\n",
    "    :param sample: sample data, type of pd.series\n",
    "    :param array_length: length of one-hot representation\n",
    "    :return: one-hot representation, type of np.array\n",
    "    \"\"\"\n",
    "    array = np.zeros([array_length])\n",
    "    for field in fields_dict:\n",
    "        # get index of array\n",
    "        if field == 'hour':\n",
    "            field_value = int(str(sample[field])[-2:])\n",
    "        else:\n",
    "            field_value = sample[field]\n",
    "        fd = fields_dict[field]\n",
    "        if field_value not in fd:\n",
    "            print('field: '+ str(field) + ', field_value: ' + str(field_value) +  ' not in fields_dict')\n",
    "        ind = fd[field_value]\n",
    "        array[ind] = 1\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7366\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "fields_train = ['hour', 'C1', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21',\n",
    "              'banner_pos', 'site_id' ,'site_domain', 'site_category', 'app_domain',\n",
    "              'app_id', 'app_category', 'device_model', 'device_type', 'device_id',\n",
    "              'device_conn_type','click']\n",
    "train = pd.read_csv('./train.csv',chunksize=batch_size)\n",
    "fields_train_dict = {}\n",
    "for field in fields_train:\n",
    "    with open('./data/dicts/' + field + '.pkl','rb') as f:\n",
    "        fields_train_dict[field] = pickle.load(f)\n",
    "with open('./data/feature2field.pkl','rb') as f:\n",
    "    feature2field = pickle.load(f)\n",
    "train_array_length = max(fields_train_dict['click'].values()) + 1\n",
    "print(train_array_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for data in train:\n",
    "    actual_batch_size = len(data)\n",
    "    batch_X = []\n",
    "    batch_y = []\n",
    "    for i in range(actual_batch_size):\n",
    "        sample = data.iloc[i,:]\n",
    "        array = one_hot_representation(sample, fields_train_dict, train_array_length)\n",
    "        batch_X.append(array[:-2])\n",
    "        batch_y.append(array[-1])\n",
    "    batch_X = np.array(batch_X)\n",
    "    batch_y = np.array(batch_y)\n",
    "    i+=1\n",
    "    if i == 10000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "f = len(fields_train) - 1\n",
    "p = train_array_length - 2\n",
    "lr = 0.01 \n",
    "reg_l1 = 2e-3\n",
    "reg_l2 = 0\n",
    "feature2field = feature2field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float32', [batch_size, p])\n",
    "y = tf.placeholder('int64', [None,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('linear_layer'):\n",
    "    b = tf.get_variable('bias', shape=[2], initializer=tf.zeros_initializer())\n",
    "    w1 = tf.get_variable('w1', shape=[p, 2], initializer=tf.truncated_normal_initializer(mean=0,stddev=1e-2))\n",
    "    linear_terms = tf.add(tf.matmul(x, w1) , b)\n",
    "\n",
    "with tf.variable_scope('field_aware_interaction_layer'):\n",
    "    v = tf.get_variable('v', shape=[p, f, k], dtype='float32',\n",
    "                                initializer=tf.truncated_normal_initializer(mean=0, stddev=0.01))\n",
    "    field_aware_interaction_terms = tf.constant(0, dtype='float32')\n",
    "    for i in range(p):\n",
    "        for j in range(i+1, p):\n",
    "            field_aware_interaction_terms += tf.multiply(\n",
    "            tf.reduce_sum(tf.multiply(v[i,feature2field[j]], v[j,feature2field[i]])),\n",
    "            tf.multiply(x[:,i],x[:,j]))\n",
    "y_out = linear_terms + field_aware_interaction_terms\n",
    "y_out_prob = tf.nn.softmax(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.y, logits=self.y_out)\n",
    "    mean_loss = tf.reduce_mean(cross_entropy)\n",
    "with tf.variable_scope('loss'):\n",
    "    correct_prediction = tf.equal(tf.cast(tf.argmax(y_out,1), tf.int64), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "optimizer = tf.train.AdagradDAOptimizer(lr)\n",
    "train_op = optimizer.minimize(mean_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
