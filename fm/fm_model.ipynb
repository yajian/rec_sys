{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '../data/train.csv'\n",
    "test_file = '../data/test.csv'\n",
    "NUMERIC_COLS = [\n",
    "    \"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\", \"ps_car_12\", \"ps_car_13\",\n",
    "    \"ps_car_14\", \"ps_car_15\"\n",
    "]\n",
    "IGNORE_COLS = [\n",
    "    \"id\", \"target\", \"ps_calc_01\", \"ps_calc_02\", \"ps_calc_03\", \"ps_calc_04\",\n",
    "    \"ps_calc_05\", \"ps_calc_06\", \"ps_calc_07\", \"ps_calc_08\", \"ps_calc_09\",\n",
    "    \"ps_calc_10\", \"ps_calc_11\", \"ps_calc_12\", \"ps_calc_13\", \"ps_calc_14\",\n",
    "    \"ps_calc_15_bin\", \"ps_calc_16_bin\", \"ps_calc_17_bin\", \"ps_calc_18_bin\",\n",
    "    \"ps_calc_19_bin\", \"ps_calc_20_bin\"\n",
    "]\n",
    "dfTrain = pd.read_csv(train_file)\n",
    "dfTest = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangyajian/repo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([dfTrain, dfTest])\n",
    "# 特征字典，key是每一列，即每个field，value是每个值对应的feature_id\n",
    "feature_dict = {}\n",
    "# 特征总数量\n",
    "total_feature = 0\n",
    "for col in df.columns:\n",
    "    if col in IGNORE_COLS:\n",
    "        continue\n",
    "    elif col in NUMERIC_COLS:\n",
    "        # 数字类型列，作为一个特征\n",
    "        feature_dict[col] = total_feature\n",
    "        total_feature += 1\n",
    "    else:\n",
    "        # 查看这一列有多少个unique的值\n",
    "        unique_val = df[col].unique()\n",
    "        feature_dict[col] = dict(\n",
    "            zip(unique_val,\n",
    "                range(total_feature,\n",
    "                      len(unique_val) + total_feature)))\n",
    "        total_feature += len(unique_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = dfTrain[['target']].values.tolist()\n",
    "dfTrain.drop(['target', 'id'], axis=1, inplace=True)\n",
    "train_feature_index = dfTrain.copy()\n",
    "train_feature_value = dfTrain.copy()\n",
    "for col in train_feature_index.columns:\n",
    "    if col in IGNORE_COLS:\n",
    "        train_feature_index.drop(col, axis=1, inplace=True)\n",
    "        train_feature_value.drop(col, axis=1, inplace=True)\n",
    "        continue\n",
    "    elif col in NUMERIC_COLS:\n",
    "        train_feature_index[col] = feature_dict[col]\n",
    "    else:\n",
    "        train_feature_index[col] = train_feature_index[col].map(\n",
    "            feature_dict[col])\n",
    "        train_feature_value[col] = 1\n",
    "train_y = np.reshape(np.array(train_y), (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "\"\"\"模型参数\"\"\"\n",
    "fm_params = {\n",
    "    \"embedding_size\": 8,\n",
    "    \"deep_layer_activation\": tf.nn.relu,\n",
    "    \"epoch\": 30,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"batch_norm\": 1,\n",
    "    \"batch_norm_decay\": 0.995,\n",
    "    \"l2_reg\": 0.01,\n",
    "    \"verbose\": True,\n",
    "    \"eval_metric\": 'gini_norm',\n",
    "    \"random_seed\": 3\n",
    "}\n",
    "fm_params['feature_size'] = total_feature\n",
    "fm_params['field_size'] = len(train_feature_index.columns)\n",
    "print(total_feature)\n",
    "print(len(train_feature_index.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight\n",
    "weights = dict()\n",
    "# liearn weight\n",
    "weights['feature_embeddings'] = tf.Variable(tf.random_normal(\n",
    "    [fm_params['feature_size'], fm_params['embedding_size']], 0.0, 0.01),\n",
    "                                            name='feature_embeddings')\n",
    "weights['feature_bias'] = tf.Variable(tf.random_normal(\n",
    "    [fm_params['feature_size'], 1], 0.0, 0.01),\n",
    "                                      name='feature_bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_index = tf.placeholder(tf.int32, [None, None], name='feat_index')\n",
    "feat_value = tf.placeholder(tf.float32, [None, None], name='feat_value')\n",
    "label = tf.placeholder(tf.float32, [None, None], name='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = tf.nn.embedding_lookup(weights['feature_embeddings'], feat_index)\n",
    "reshape_feat_value = tf.reshape(feat_value, [-1, fm_params['field_size'], 1])\n",
    "embeddings = tf.multiply(embeddings, reshape_feat_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 37)\n",
      "(?, 1)\n"
     ]
    }
   ],
   "source": [
    "# first order\n",
    "first_order_weight = tf.nn.embedding_lookup(weights['feature_bias'],\n",
    "                                            feat_index)\n",
    "first_order_output = tf.reduce_sum(\n",
    "    tf.multiply(first_order_weight, reshape_feat_value), 2)\n",
    "print(first_order_output.shape)\n",
    "first_order_output = tf.reduce_sum(first_order_output, 1, keepdims=True)\n",
    "print(first_order_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 8)\n",
      "(?, 1)\n"
     ]
    }
   ],
   "source": [
    "# second order\n",
    "\n",
    "# sum square\n",
    "sum_square = tf.square(tf.reduce_sum(embeddings, 1))\n",
    "# square sum\n",
    "square_sum = tf.reduce_sum(tf.square(embeddings), 1)\n",
    "print(square_sum.shape)\n",
    "second_order_output = 0.5 * tf.reduce_sum(sum_square - square_sum, 1, keepdims=True)\n",
    "print(second_order_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/huangyajian/repo/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "output = first_order_output + second_order_output\n",
    "output = tf.nn.sigmoid(output)\n",
    "loss = tf.losses.log_loss(label, output)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=fm_params['learning_rate'],\n",
    "                                   beta1=0.9,\n",
    "                                   beta2=0.999,\n",
    "                                   epsilon=1e-8).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67144793\n",
      "0.65197283\n",
      "0.63483924\n",
      "0.61894643\n",
      "0.60371095\n",
      "0.5887092\n",
      "0.57379717\n",
      "0.5590541\n",
      "0.5446048\n",
      "0.5330095\n",
      "0.51953155\n",
      "0.50644183\n",
      "0.4937455\n",
      "0.48143566\n",
      "0.46949145\n",
      "0.45788646\n",
      "0.44660142\n",
      "0.43563005\n",
      "0.42028856\n",
      "0.40966675\n",
      "0.39935493\n",
      "0.38936085\n",
      "0.37968487\n",
      "0.37032285\n",
      "0.36126828\n",
      "0.3525144\n",
      "0.3440545\n",
      "0.33864957\n",
      "0.33085674\n",
      "0.3233325\n",
      "0.31607428\n",
      "0.3090788\n",
      "0.30234158\n",
      "0.29585683\n",
      "0.2896178\n",
      "0.28361723\n",
      "0.2679786\n",
      "0.2622391\n",
      "0.25669777\n",
      "0.2513522\n",
      "0.24619938\n",
      "0.24123569\n",
      "0.23645657\n",
      "0.23185706\n",
      "0.22743197\n",
      "0.23836872\n",
      "0.23459928\n",
      "0.23099649\n",
      "0.22755358\n",
      "0.22426412\n",
      "0.22112168\n",
      "0.21812007\n",
      "0.21525322\n",
      "0.21251522\n",
      "0.211855\n",
      "0.20943972\n",
      "0.20713228\n",
      "0.2049284\n",
      "0.20282388\n",
      "0.20081447\n",
      "0.19889608\n",
      "0.19706455\n",
      "0.19531587\n",
      "0.2006785\n",
      "0.19921757\n",
      "0.19782117\n",
      "0.19648683\n",
      "0.19521207\n",
      "0.19399454\n",
      "0.19283184\n",
      "0.19172141\n",
      "0.19066069\n",
      "0.20194356\n",
      "0.20115584\n",
      "0.20040363\n",
      "0.1996844\n",
      "0.19899568\n",
      "0.19833511\n",
      "0.19770035\n",
      "0.19708924\n",
      "0.19649959\n",
      "0.17599693\n",
      "0.17544329\n",
      "0.17489585\n",
      "0.17435555\n",
      "0.17382315\n",
      "0.17329913\n",
      "0.17278379\n",
      "0.17227712\n",
      "0.17177898\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_size = int(len(train_feature_index)/fm_params['batch_size'])\n",
    "    for i in range(fm_params['epoch']):\n",
    "        for j in range(batch_size):\n",
    "            start = i * fm_params['batch_size']\n",
    "            end = (i+1) * fm_params['batch_size']\n",
    "            end = end if end<len(train_feature_index) else len(train_feature_index)\n",
    "            feat_index_batch = train_feature_index[start:end]\n",
    "            feat_value_batch = train_feature_value[start:end]\n",
    "            label_batch = train_y[start:end]\n",
    "            feed_dict = {\n",
    "                feat_index:feat_index_batch,\n",
    "                feat_value:feat_value_batch,\n",
    "                label:label_batch\n",
    "            }\n",
    "            l,o = sess.run([loss,optimizer], feed_dict)\n",
    "            print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
